{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to MkDocs For full documentation visit mkdocs.org . Commands mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit. Project layout mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Home"},{"location":"#welcome-to-mkdocs","text":"For full documentation visit mkdocs.org .","title":"Welcome to MkDocs"},{"location":"#commands","text":"mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit.","title":"Commands"},{"location":"#project-layout","text":"mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Project layout"},{"location":"COV%20816/01_B01/","text":"1 BASICS OF IMAGES 1.1 Definition of a Digital Image An image is a two-dimensional array of values representing light intensity. For the purposes of image processing, the term image refers to a digital image. An image is a function of the light intensity: f(x, y) where f is the brightness of the point \\((x, y\\)), and x and y represent the spatial coordinates of a picture element (abbreviated pixel). By convention, the spatial reference of the pixel with the coordinates (0, 0) is located at the top, left corner of the image. Notice in Figure 1-1 that the value of x increases moving from left to right, and the value of y increases from top to bottom. [FIGURE WILL BE HERE] Figure 1-1. Spatial Reference of the (0, 0) Pixel. In digital image processing, an imaging sensor converts an image into a discrete number of pixels. The imaging sensor assigns to each pixel a numeric location and a gray level or color value that specifies the brightness or color of the pixel. 1.2 Properties of a Digitized Image A digitized image has three basic properties: resolution , definition , and number of planes . 1.2.1 Image Resolution The spatial resolution of an image is its number of rows and columns of pixels. An image composed of m columns and n rows has a resolution of \\(m\\times n\\). This image has m pixels along its horizontal axis and n pixels along its vertical axis. 1.2.2 Image Definition The definition of an image indicates the number of shades that you can see in the image. The bit depth of an image is the number of bits used to encode the value of a pixel. For a given bit depth of \\(n\\), the image has an image definition of \\(2^n\\), meaning a pixel can have \\(2^n\\) different values. For example, if \\(n\\) equals 8-bits, a pixel can take 256 different values ranging from 0 to 255. If \\(n\\) equals 16 bits, a pixel can take 65,536 different values ranging from 0 to 65,535 or from \u201332,768 to 32,767. The manner in which you encode your image depends on the nature of the image acquisition device, the type of image processing you need to use, and the type of analysis you need to perform. For example, 8-bit encoding is sufficient if you need to obtain the shape information of objects in an image. However, if you need to precisely measure the light intensity of an image or region in an image, you must use 16-bit or floating-point encoding. TIP: Use color encoded images when your machine vision or image processing application depends on the color content of the objects you are inspecting or analyzing. 1.2.3 Number of Planes The number of planes in an image corresponds to the number of arrays of pixels that compose the image. A grayscale or pseudo-color image is composed of one plane, while a true-color image is composed of three planes\u2014one each for the red component, blue component, and green component. In true-color images, the color component intensities of a pixel are coded into three different values. The color image is the combination of three arrays of pixels corresponding to the red , green , and blue components in an RGB image. HSL images are defined by their hue , saturation , and luminance values. 1.3 Image Types We can talk about three main types of images: grayscale, color, and complex images . 1.3.1 Grayscale Images A grayscale image is composed of a single plane of pixels. Each pixel is encoded using one of the following single numbers: An 8-bit unsigned integer representing grayscale values between 0 and 255. A 16-bit signed integer representing grayscale values between \u201332,768 and +32,767. A single precision floating point number (encoded using four bytes) representing grayscale values ranging from \\(-\\infty\\) to \\(+\\infty\\). 1.3.2 Color Images A color image is encoded in memory as either an RGB or HSL image. Color image pixels are a composite of four values. RGB images store color information using 8 bits each for the red , green , and blue planes. HSL images store color information using 8 bits each for hue , saturation , and luminance . In all of the color models, an additional 8-bit value goes unused. This representation is known as 4\\(\\times\\)8-bit or 32-bit encoding. 1.3.3 Complex Images A complex image contains the frequency information of a grayscale image. Create a complex image by applying a Fast Fourier transform (FFT) to a grayscale image. When you transform a grayscale image into a complex image, you can perform frequency domain operations on the image. Each pixel in a complex image is encoded as two single-precision floating-point values, which represent the real and imaginary components of the complex pixel. You can extract the following four components from a complex image: the real part , imaginary part , magnitude , and phase . 1.4 Image Files An image file is composed of a header followed by pixel values. Depending on the file format, the header contains image information about the horizontal and vertical resolution, pixel definition, and the original palette. Image files may also store information about calibration, pattern matching templates, and overlays. The following are common image file formats: Bitmap ( BMP ) Tagged image file format ( TIFF ). Portable network graphics ( PNG ): Offers the capability of storing image information about spatial calibration, pattern matching templates, and overlays. Joint Photographic Experts Group format ( JPEG ). National Instruments image file format ( AIPD ): Used for saving floating-point, complex, and HSL images. Standard formats for 8-bit grayscale and RGB color images are BMP, TIFF, PNG, JPEG, and AIPD. Standard formats for 16-bit grayscale and complex images are PNG and AIPD. 1.5 Color Spaces Color spaces allow you to represent a color. A color space is a subspace within a three-dimensional coordinate system where each color is represented by a point. You can use color spaces to facilitate the description of colors between persons, machines, or software programs. Various industries and applications use a number of different color spaces. Humans perceive color according to parameters such as brightness, hue, and intensity, while computers perceive color as a combination of red, green, and blue. The printing industry uses cyan, magenta, and yellow to specify color. The following is a list of common color spaces. RGB: Based on red, green, and blue. Used by computers to display images. HSL: Based on hue, saturation, and luminance. Used in image processing applications. CIE: Based on brightness, hue, and colorfulness. Defined by the Commission Internationale de l\u2019Eclairage (International Commission on Illumination) as the different sensations of color that the human brain perceives. CMY: Based on cyan, magenta, and yellow. Used by the printing industry. YIQ: Separates the luminance information (Y) from the color information (I and Q). Used for TV broadcasting. When to Use: You must define a color space every time you process color images. If you expect the lighting conditions to vary considerably during your color machine vision application, use the HSL color space. The HSL color space provides more accurate color information than the RGB space when running color processing functions, such as color matching, color location, and color pattern matching. If you do not expect the lighting conditions to vary considerably during your application, and you can easily define the colors you are looking for using red, green, and blue, use the RGB space. Also, use the RGB space if you want only to display color images, but not process them, in your application. The RGB space reproduces an image as you would expect to see it. 1.5.1 Concepts Because color is the brain\u2019s reaction to a specific visual stimulus, color is best described by the different sensations of color that the human brain perceives. The color-sensitive cells in the eye\u2019s retina sample color using three bands that correspond to red, green, and blue light. The signals from these cells travel to the brain where they combine to produce different sensations of colors. The Commission Internationale de l\u2019Eclairage has defined the following sensations: Brightness: The sensation of an area exhibiting more or less light Hue: The sensation of an area appearing similar to a combination of red, green, and blue Colorfulness: The sensation of an area appearing to exhibit more or less of its hue Lightness: The sensation of an area\u2019s brightness relative to a reference white in the scene Chroma: The colorfulness of an area with respect to a reference white in the scene Saturation: The colorfulness of an area relative to its brightness The trichromatic theory describes how three separate lights (red, green, and blue) can be combined to match any visible color. This theory is based on the three color sensors that the eye uses. Printing and photography use the trichromatic theory as the basis for combining three different colored dyes to reproduce colors in a scene. Computer color spaces also use three parameters to define a color. Most color spaces are geared toward displaying images with hardware, such as color monitors and printers, or toward applications that manipulate color information, such as computer graphics and image processing. Color CRT monitors, major of color video cameras, and most computer graphics systems use the RGB color space. The HSL space, combined with RGB and YIQ , is frequently used in applications that manipulate color, such as image processing. The color picture publishing industry uses the CMY color space, also known as CMYK . The YIQ space is the standard for color TV broadcast. 1.5.2 The RGB Color Space The RGB color space is the most commonly used color space. The human eye receives color information in separate red , green , and blue components through cones, the color receptors present in the human eye. These three colors are known as additive primary colors. In an additive color system, the human brain processes the three primary light sources and combines them to compose a single color image . The three primary color components can combine to reproduce almost all other possible colors. You can visualize the RGB space as a 3-dimensional cube with red, green, and blue at the corners of each axis, as shown in Figure 1.5-1. Black is at the origin, while white is at the opposite corner of the cube. Each side of the cube has a value between 0 and 1. Along each axis of the RGB cube, the colors range from no contribution of that component to a fully saturated color. Any point, or color, within the cube is specified by three numbers: an R , G , B triple. The diagonal line of the cube from black \\((0, 0, 0)\\) to white \\((1, 1, 1\\)) represents all the grayscale values or where all of the red, green, and blue components are equal. Different computer hardware and software combinations use different ranges for the colors. Common combinations are 0\u2013255 and 0\u201365,535 for each component. To map color values within these ranges to values in the RGB cube, divide the color values by the maximum value that the range can take. [A FIGURE WILL BE HERE] Figure 1.5-1: RGB Cube. The RGB color space lies within the perceptual space of humans. In other words, the RGB cube represents fewer colors than we can see. The RGB space simplifies the design of computer monitors, but it is not ideal for all applications. In the RGB color space, the red, green, and blue color components are all necessary to describe a color. Therefore, RGB is not as intuitive as other color spaces. The HSL color space describes color using only the hue component, which makes HSL the best choice for many image processing applications, such as color matching. 1.5.3 HSL Color Space The HSL color space was developed to put color in terms that are easy for humans to quantify . H ue, S aturation, and L ightness are characteristics that distinguish one color from another in the HSL space. Hue corresponds to the dominant wavelength of the color. The hue component is a color, such as orange, green, or violet. You can visualize the range of hues as a rainbow. Saturation refers to the amount of white added to the hue and represents the relative purity of a color. A color without any white is fully saturated. The degree of saturation is inversely proportional to the amount of white light added. Colors such as pink (red and white) and lavender (purple and white) are less saturated than red and purple. Lightness embodies the chromatic notion of luminance, or the amplitude or power of light. Chromaticity is the combination of hue and saturation, and the relationship between chromacity and lightness characterizes a color. Systems that manipulate hue use the HSL color space, which also can be written as HSB (Hue, Saturation, and Brightness) or HSV (Hue, Saturation, and Value). 1.5.4 CIE L*a*b* Color Space CIE 1976 L*a*b* , one of the CIE-based color spaces, is a way to linearize the perceptibility of color differences. The nonlinear relations for L* , a* , and b* mimic the logarithmic response of the eye. 1.5.5 CMY Color Space CMY is another set of familiar primary colors: cyan, magenta, and yellow. CMY is a subtractive color space in which these primary colors are subtracted from white light to produce the desired color. The CMY color space is the basis of most color printing and photography processes. CMY is the complement of the RGB color space because cyan, magenta, and yellow are the complements of red, green, and blue . 1.5.6 YIQ Color Space The YIQ space is the primary color space adopted by the National Television System Committee (NTSC) for color TV broadcasting. It is a linear transformation of the RGB cube for transmission efficiency and for maintaining compatibility with monochrome television standards. The Y component of the YIQ system provides all the video information that a monochrome television set requires. The main advantage of the YIQ space for image processing is that the luminance information (Y) is decoupled from the color information (I and Q). Because luminance is proportional to the amount of light perceived by the eye, modifications to the grayscale appearance of the image do not affect the color information.","title":"Bloco 01 - Basic Concepts"},{"location":"COV%20816/01_B01/#1-basics-of-images","text":"","title":"1 BASICS OF IMAGES"},{"location":"COV%20816/01_B01/#11-definition-of-a-digital-image","text":"An image is a two-dimensional array of values representing light intensity. For the purposes of image processing, the term image refers to a digital image. An image is a function of the light intensity: f(x, y) where f is the brightness of the point \\((x, y\\)), and x and y represent the spatial coordinates of a picture element (abbreviated pixel). By convention, the spatial reference of the pixel with the coordinates (0, 0) is located at the top, left corner of the image. Notice in Figure 1-1 that the value of x increases moving from left to right, and the value of y increases from top to bottom. [FIGURE WILL BE HERE] Figure 1-1. Spatial Reference of the (0, 0) Pixel. In digital image processing, an imaging sensor converts an image into a discrete number of pixels. The imaging sensor assigns to each pixel a numeric location and a gray level or color value that specifies the brightness or color of the pixel.","title":"1.1 Definition of a Digital Image"},{"location":"COV%20816/01_B01/#12-properties-of-a-digitized-image","text":"A digitized image has three basic properties: resolution , definition , and number of planes .","title":"1.2 Properties of a Digitized Image"},{"location":"COV%20816/01_B01/#121-image-resolution","text":"The spatial resolution of an image is its number of rows and columns of pixels. An image composed of m columns and n rows has a resolution of \\(m\\times n\\). This image has m pixels along its horizontal axis and n pixels along its vertical axis.","title":"1.2.1 Image Resolution"},{"location":"COV%20816/01_B01/#122-image-definition","text":"The definition of an image indicates the number of shades that you can see in the image. The bit depth of an image is the number of bits used to encode the value of a pixel. For a given bit depth of \\(n\\), the image has an image definition of \\(2^n\\), meaning a pixel can have \\(2^n\\) different values. For example, if \\(n\\) equals 8-bits, a pixel can take 256 different values ranging from 0 to 255. If \\(n\\) equals 16 bits, a pixel can take 65,536 different values ranging from 0 to 65,535 or from \u201332,768 to 32,767. The manner in which you encode your image depends on the nature of the image acquisition device, the type of image processing you need to use, and the type of analysis you need to perform. For example, 8-bit encoding is sufficient if you need to obtain the shape information of objects in an image. However, if you need to precisely measure the light intensity of an image or region in an image, you must use 16-bit or floating-point encoding. TIP: Use color encoded images when your machine vision or image processing application depends on the color content of the objects you are inspecting or analyzing.","title":"1.2.2 Image Definition"},{"location":"COV%20816/01_B01/#123-number-of-planes","text":"The number of planes in an image corresponds to the number of arrays of pixels that compose the image. A grayscale or pseudo-color image is composed of one plane, while a true-color image is composed of three planes\u2014one each for the red component, blue component, and green component. In true-color images, the color component intensities of a pixel are coded into three different values. The color image is the combination of three arrays of pixels corresponding to the red , green , and blue components in an RGB image. HSL images are defined by their hue , saturation , and luminance values.","title":"1.2.3 Number of Planes"},{"location":"COV%20816/01_B01/#13-image-types","text":"We can talk about three main types of images: grayscale, color, and complex images .","title":"1.3 Image Types"},{"location":"COV%20816/01_B01/#131-grayscale-images","text":"A grayscale image is composed of a single plane of pixels. Each pixel is encoded using one of the following single numbers: An 8-bit unsigned integer representing grayscale values between 0 and 255. A 16-bit signed integer representing grayscale values between \u201332,768 and +32,767. A single precision floating point number (encoded using four bytes) representing grayscale values ranging from \\(-\\infty\\) to \\(+\\infty\\).","title":"1.3.1 Grayscale Images"},{"location":"COV%20816/01_B01/#132-color-images","text":"A color image is encoded in memory as either an RGB or HSL image. Color image pixels are a composite of four values. RGB images store color information using 8 bits each for the red , green , and blue planes. HSL images store color information using 8 bits each for hue , saturation , and luminance . In all of the color models, an additional 8-bit value goes unused. This representation is known as 4\\(\\times\\)8-bit or 32-bit encoding.","title":"1.3.2 Color Images"},{"location":"COV%20816/01_B01/#133-complex-images","text":"A complex image contains the frequency information of a grayscale image. Create a complex image by applying a Fast Fourier transform (FFT) to a grayscale image. When you transform a grayscale image into a complex image, you can perform frequency domain operations on the image. Each pixel in a complex image is encoded as two single-precision floating-point values, which represent the real and imaginary components of the complex pixel. You can extract the following four components from a complex image: the real part , imaginary part , magnitude , and phase .","title":"1.3.3 Complex Images"},{"location":"COV%20816/01_B01/#14-image-files","text":"An image file is composed of a header followed by pixel values. Depending on the file format, the header contains image information about the horizontal and vertical resolution, pixel definition, and the original palette. Image files may also store information about calibration, pattern matching templates, and overlays. The following are common image file formats: Bitmap ( BMP ) Tagged image file format ( TIFF ). Portable network graphics ( PNG ): Offers the capability of storing image information about spatial calibration, pattern matching templates, and overlays. Joint Photographic Experts Group format ( JPEG ). National Instruments image file format ( AIPD ): Used for saving floating-point, complex, and HSL images. Standard formats for 8-bit grayscale and RGB color images are BMP, TIFF, PNG, JPEG, and AIPD. Standard formats for 16-bit grayscale and complex images are PNG and AIPD.","title":"1.4 Image Files"},{"location":"COV%20816/01_B01/#15-color-spaces","text":"Color spaces allow you to represent a color. A color space is a subspace within a three-dimensional coordinate system where each color is represented by a point. You can use color spaces to facilitate the description of colors between persons, machines, or software programs. Various industries and applications use a number of different color spaces. Humans perceive color according to parameters such as brightness, hue, and intensity, while computers perceive color as a combination of red, green, and blue. The printing industry uses cyan, magenta, and yellow to specify color. The following is a list of common color spaces. RGB: Based on red, green, and blue. Used by computers to display images. HSL: Based on hue, saturation, and luminance. Used in image processing applications. CIE: Based on brightness, hue, and colorfulness. Defined by the Commission Internationale de l\u2019Eclairage (International Commission on Illumination) as the different sensations of color that the human brain perceives. CMY: Based on cyan, magenta, and yellow. Used by the printing industry. YIQ: Separates the luminance information (Y) from the color information (I and Q). Used for TV broadcasting. When to Use: You must define a color space every time you process color images. If you expect the lighting conditions to vary considerably during your color machine vision application, use the HSL color space. The HSL color space provides more accurate color information than the RGB space when running color processing functions, such as color matching, color location, and color pattern matching. If you do not expect the lighting conditions to vary considerably during your application, and you can easily define the colors you are looking for using red, green, and blue, use the RGB space. Also, use the RGB space if you want only to display color images, but not process them, in your application. The RGB space reproduces an image as you would expect to see it.","title":"1.5 Color Spaces"},{"location":"COV%20816/01_B01/#151-concepts","text":"Because color is the brain\u2019s reaction to a specific visual stimulus, color is best described by the different sensations of color that the human brain perceives. The color-sensitive cells in the eye\u2019s retina sample color using three bands that correspond to red, green, and blue light. The signals from these cells travel to the brain where they combine to produce different sensations of colors. The Commission Internationale de l\u2019Eclairage has defined the following sensations: Brightness: The sensation of an area exhibiting more or less light Hue: The sensation of an area appearing similar to a combination of red, green, and blue Colorfulness: The sensation of an area appearing to exhibit more or less of its hue Lightness: The sensation of an area\u2019s brightness relative to a reference white in the scene Chroma: The colorfulness of an area with respect to a reference white in the scene Saturation: The colorfulness of an area relative to its brightness The trichromatic theory describes how three separate lights (red, green, and blue) can be combined to match any visible color. This theory is based on the three color sensors that the eye uses. Printing and photography use the trichromatic theory as the basis for combining three different colored dyes to reproduce colors in a scene. Computer color spaces also use three parameters to define a color. Most color spaces are geared toward displaying images with hardware, such as color monitors and printers, or toward applications that manipulate color information, such as computer graphics and image processing. Color CRT monitors, major of color video cameras, and most computer graphics systems use the RGB color space. The HSL space, combined with RGB and YIQ , is frequently used in applications that manipulate color, such as image processing. The color picture publishing industry uses the CMY color space, also known as CMYK . The YIQ space is the standard for color TV broadcast.","title":"1.5.1 Concepts"},{"location":"COV%20816/01_B01/#152-the-rgb-color-space","text":"The RGB color space is the most commonly used color space. The human eye receives color information in separate red , green , and blue components through cones, the color receptors present in the human eye. These three colors are known as additive primary colors. In an additive color system, the human brain processes the three primary light sources and combines them to compose a single color image . The three primary color components can combine to reproduce almost all other possible colors. You can visualize the RGB space as a 3-dimensional cube with red, green, and blue at the corners of each axis, as shown in Figure 1.5-1. Black is at the origin, while white is at the opposite corner of the cube. Each side of the cube has a value between 0 and 1. Along each axis of the RGB cube, the colors range from no contribution of that component to a fully saturated color. Any point, or color, within the cube is specified by three numbers: an R , G , B triple. The diagonal line of the cube from black \\((0, 0, 0)\\) to white \\((1, 1, 1\\)) represents all the grayscale values or where all of the red, green, and blue components are equal. Different computer hardware and software combinations use different ranges for the colors. Common combinations are 0\u2013255 and 0\u201365,535 for each component. To map color values within these ranges to values in the RGB cube, divide the color values by the maximum value that the range can take. [A FIGURE WILL BE HERE] Figure 1.5-1: RGB Cube. The RGB color space lies within the perceptual space of humans. In other words, the RGB cube represents fewer colors than we can see. The RGB space simplifies the design of computer monitors, but it is not ideal for all applications. In the RGB color space, the red, green, and blue color components are all necessary to describe a color. Therefore, RGB is not as intuitive as other color spaces. The HSL color space describes color using only the hue component, which makes HSL the best choice for many image processing applications, such as color matching.","title":"1.5.2 The RGB Color Space"},{"location":"COV%20816/01_B01/#153-hsl-color-space","text":"The HSL color space was developed to put color in terms that are easy for humans to quantify . H ue, S aturation, and L ightness are characteristics that distinguish one color from another in the HSL space. Hue corresponds to the dominant wavelength of the color. The hue component is a color, such as orange, green, or violet. You can visualize the range of hues as a rainbow. Saturation refers to the amount of white added to the hue and represents the relative purity of a color. A color without any white is fully saturated. The degree of saturation is inversely proportional to the amount of white light added. Colors such as pink (red and white) and lavender (purple and white) are less saturated than red and purple. Lightness embodies the chromatic notion of luminance, or the amplitude or power of light. Chromaticity is the combination of hue and saturation, and the relationship between chromacity and lightness characterizes a color. Systems that manipulate hue use the HSL color space, which also can be written as HSB (Hue, Saturation, and Brightness) or HSV (Hue, Saturation, and Value).","title":"1.5.3 HSL Color Space"},{"location":"COV%20816/01_B01/#154-cie-lab-color-space","text":"CIE 1976 L*a*b* , one of the CIE-based color spaces, is a way to linearize the perceptibility of color differences. The nonlinear relations for L* , a* , and b* mimic the logarithmic response of the eye.","title":"1.5.4 CIE L*a*b* Color Space"},{"location":"COV%20816/01_B01/#155-cmy-color-space","text":"CMY is another set of familiar primary colors: cyan, magenta, and yellow. CMY is a subtractive color space in which these primary colors are subtracted from white light to produce the desired color. The CMY color space is the basis of most color printing and photography processes. CMY is the complement of the RGB color space because cyan, magenta, and yellow are the complements of red, green, and blue .","title":"1.5.5 CMY Color Space"},{"location":"COV%20816/01_B01/#156-yiq-color-space","text":"The YIQ space is the primary color space adopted by the National Television System Committee (NTSC) for color TV broadcasting. It is a linear transformation of the RGB cube for transmission efficiency and for maintaining compatibility with monochrome television standards. The Y component of the YIQ system provides all the video information that a monochrome television set requires. The main advantage of the YIQ space for image processing is that the luminance information (Y) is decoupled from the color information (I and Q). Because luminance is proportional to the amount of light perceived by the eye, modifications to the grayscale appearance of the image do not affect the color information.","title":"1.5.6 YIQ Color Space"},{"location":"COV%20816/02_B02/","text":"2 IMAGE ACQUISITION This block section addressess how to set up an imaging system and calibrate the imaging setup so that you can convert pixel-coordinates to real-world coordinates. Converting pixel-coordinates to real-world coordinates is useful when you need to make accurate measurements from inspection images using real-world units 2.1 System Setup [TO BE FILLED] 2.2 Calibration [TO BE FILLED]","title":"Bloco 02 - Image Aquisition"},{"location":"COV%20816/02_B02/#2-image-acquisition","text":"This block section addressess how to set up an imaging system and calibrate the imaging setup so that you can convert pixel-coordinates to real-world coordinates. Converting pixel-coordinates to real-world coordinates is useful when you need to make accurate measurements from inspection images using real-world units","title":"2 IMAGE ACQUISITION"},{"location":"COV%20816/02_B02/#21-system-setup","text":"[TO BE FILLED]","title":"2.1 System Setup"},{"location":"COV%20816/02_B02/#22-calibration","text":"[TO BE FILLED]","title":"2.2 Calibration"},{"location":"COV%20816/ementa/","text":"EMENTA DA DISCIPLINA COV 816 - PROCESSAMENTO DE IMAGENS (PROGRAMA DE ENG\u00aa OCE\u00c2NICA - 2023/1) Identifica\u00e7\u00e3o ITEM DESCRI\u00c7\u00c3O NOME: PROCESSAMENTO E AN\u00c1LISE DE IMAGENS NA ENGENHARIA NAVAL E OCE\u00c2NICA C\u00d3DIGO: COV-816 CARGA HOR\u00c1RIA: 45 HORAS \u00c1REA: ENGENHARIAS/ENGENHARIA NAVAL E OCE\u00c2NICA CR\u00c9DITOS: 3,0 P\u00fablico Alvo Estudantes de gradua\u00e7\u00e3o e p\u00f3s-gradua\u00e7\u00e3o que atuem nas \u00e1reas de engenharia. Objetivos GERAL: Proporcionar aos alunos um estudo aprofundado dos princ\u00edpios e t\u00e9cnicas de processamento de imagens nos seguintes t\u00f3picos: Aquisi\u00e7\u00e3o de imagens (equipamentos, amostragem, quantiza\u00e7\u00e3o e representa\u00e7\u00e3o de cores). Aprimoramento de imagens digitais no dom\u00ednios espacial (suaviza\u00e7\u00e3o de nitidez, detec\u00e7\u00e3o de bordas, limiariza\u00e7\u00e3o, equaliza\u00e7\u00e3o de histogramas, opera\u00e7\u00f5es morfol\u00f3gicas). Convers\u00e3o, segmenta\u00e7\u00e3o e representa\u00e7\u00e3o de imagens. Identifica\u00e7\u00e3o e seguimento de padr\u00f5es. Automa\u00e7\u00e3o dos modelos de processamento de imagens. ESPEC\u00cdFICO: Ao final do curso, os estudantes devem ser capazes de projetar e implementar operadores e processamentos diversos sobre imagens digitais de diversas modalidades e protocolos em problemas de estudo da Engenharia Naval e Oce\u00e2nica. Metodologia A disciplina est\u00e1 dividida em cinco blocos, cujos conte\u00fados ser\u00e3o ministrados com base em um plano particular de trabalho, e duas avalia\u00e7\u00f5es. Os blocos com seus conte\u00fados e planos de trabalho, e os pontos de avalia\u00e7\u00e3o, s\u00e3o discriminados na tabela a seguir: Bloco 1 - Conceitos b\u00e1sicos (4 aulas) CONTE\u00daDO: - Defini\u00e7\u00e3o da Imagem Digital: Conceito geral da imagem digital e suas propriedades principais - Tipos de Imagens e Arquivos de Imagem: Imagens em tons de cinza, imagens a cor, e imagens complexas. - Espa\u00e7os de cor: Apresenta\u00e7\u00e3o dos principais espa\u00e7os de cor usados nas imagens digitais (RGB, HSL, CIE-Lab). - Apresenta\u00e7\u00e3o do conte\u00fado do curso. PLANO DE TRABALHO: - Aplica\u00e7\u00e3o ao vivo dos conceitos no software ImageJ/FIJI. - Estudo da t\u00e9cnica de fotoluminesc\u00eancia. - Opera\u00e7\u00f5es de cor e pseudo-cor nas imagens. - Melhora digital das imagens. Bloco 2 - Aquisi\u00e7\u00e3o de imagens (4 aulas) CONTE\u00daDO: - Aquisi\u00e7\u00e3o de imagens: Conceitos de Resolu\u00e7\u00e3o, Contraste, Profundidade de Campo, Perspectiva, Distor\u00e7\u00e3o. - Calibra\u00e7\u00e3o Espacial: Processo de Calibra\u00e7\u00e3o, Sistema de Coordenadas, Algoritmos de Calibra\u00e7\u00e3o, Corre\u00e7\u00f5es de Imagem. PLANO DE TRABALHO: - Aquisi\u00e7\u00e3o de imagens com webcam. - Aquisi\u00e7\u00e3o de imagens com c\u00e2meras de uso industrial/cient\u00edfico. - Rectifica\u00e7\u00e3o de imagens. - Correla\u00e7\u00e3o de unidades de imagem e do mundo real. - Protocolos de calibra\u00e7\u00e3o. EXAME PARCIAL (B1 - B2) Bloco 3 - An\u00e1lise e processamento de imagens (6 aulas) CONTE\u00daDO: An\u00e1lise de imagens: Histograma, Linha de Perfil, Medidas de Intensidade. Processamento de imagens: LUT, Convolu\u00e7\u00e3o, Filtros Espaciais, Binariza\u00e7\u00e3o, Morfologia de Imagens Bin\u00e1rias, Detec\u00e7\u00e3o de Bordas. PLANO DE TRABALHO: Filtragem das imagens retificadas no Bloco 2. Medi\u00e7\u00e3o de part\u00edculas e elementos da imagem. Programa\u00e7\u00e3o de Macros. Automa\u00e7\u00e3o do processamento e filtragem dos elementos da imagem digital. Bloco 4 - Metrologia por imagens (6 aulas) CONTE\u00daDO: Medi\u00e7\u00e3o em imagens: Medi\u00e7\u00e3o de regi\u00f5es, medi\u00e7\u00e3o de part\u00edculas. Segmenta\u00e7\u00e3o e Classifica\u00e7\u00e3o: T\u00e9cnicas de segmenta\u00e7\u00e3o de objetos e classifica\u00e7\u00e3o de part\u00edculas, automa\u00e7\u00e3o do processo de medi\u00e7\u00e3o/classifica\u00e7\u00e3o. PLANO DE TRABALHO: Filtragem das imagens retificadas no Bloco 2. Medi\u00e7\u00e3o de part\u00edculas e elementos da imagem. Programa\u00e7\u00e3o de Macros. Automa\u00e7\u00e3o do processamento e filtragem dos elementos da imagem digital. Bloco 5 - Apresenta\u00e7\u00f5es de Projetos por Equipe (2 aulas) CONTE\u00daDO: Discuss\u00e3o geral e resolu\u00e7\u00e3o de d\u00favidas gerais do curso. PLANO DE TRABALHO: Equipes apresentam projeto de processamento de imagens aplicado a problemas de relev\u00e2ncia da \u00e1rea de estudo. EXAME FINAL (B3 - B4) Ementa BLOCO DESCRI\u00c7\u00c3O B1 - Conceitos b\u00e1sicos Defini\u00e7\u00e3o da Imagem Digital: Conceito geral da imagem digital e suas propriedades principais. Tipos de Imagens e Arquivos de Imagem: Imagens em tons de cinza, imagens a cor, e imagens complexas. Espa\u00e7os de cor: Apresenta\u00e7\u00e3o dos espa\u00e7os de cor RGB, HSL e CIE-Lab usados nas imagens digitais. B2 - Aquisi\u00e7\u00e3o de imagens Aquisi\u00e7\u00e3o de imagens: Conceitos de Resolu\u00e7\u00e3o, Contraste, Profundidade de Campo, Perspectiva, Distor\u00e7\u00e3o. Calibra\u00e7\u00e3o Espacial: Processo de Calibra\u00e7\u00e3o, Sistema de Coordenadas, Algoritmos de Calibra\u00e7\u00e3o, Corre\u00e7\u00f5es de Imagem. B3 - An\u00e1lise e processamento de imagens An\u00e1lise de imagens: Histograma, Linha de Perfil, Medidas de Intensidade. Processamento de imagens: Convolu\u00e7\u00e3o, Filtros Espaciais, Binariza\u00e7\u00e3o, Morfologia de Imagens Bin\u00e1rias, Detec\u00e7\u00e3o de Bordas. B4 - Metrologia por imagens Medi\u00e7\u00e3o em imagens: Medi\u00e7\u00e3o de regi\u00f5es, medi\u00e7\u00e3o de part\u00edculas. Segmenta\u00e7\u00e3o e Classifica\u00e7\u00e3o: T\u00e9cnicas de segmenta\u00e7\u00e3o de objetos e classifica\u00e7\u00e3o de part\u00edculas, automa\u00e7\u00e3o do processo de medi\u00e7\u00e3o/classifica\u00e7\u00e3o. B5 - Apresenta\u00e7\u00e3o de Projetos Discuss\u00e3o geral e resolu\u00e7\u00e3o de d\u00favidas gerais do curso. Bibliografia Bibliografia Complementar ( Livro did\u00e1tico ) [1] BURGER, W., BURGE, M. J. Principles of digital image processing. 1: Fundamental techniques . London, Springer, 2009. Conceitos B\u00e1sicos [2] GONZALEZ, R. C., WOODS, R. E. Digital image processing . 2nd ed., Internat. Upper Saddle River, NJ, Prentice-Hall, 2002. [3] J\u00c4HNE, B. Digital image processing. 6th ed. Berlin\u202f; New York, Springer, 2005. [4] SZELISKI, R. Computer vision: algorithms and applications . London Heidelberg, Springer, 2011. Aquisi\u00e7\u00e3o, an\u00e1lise e processamento de imagens [5] CORKE, P. I. Robotics, vision and control: fundamental algorithms in MATLAB . Berlin, Springer, 2011. (Springer tracts in advanced robotics, v. 73). [6] RELF, C. G. Image acquisition and processing with LabVIEW. Boca Raton , CRC Press, 2004. (Image processing series). T\u00e9cnicas de Processamento de Imagens [7] BURGER, W., BURGE, M. J. Principles of digital image processing. 2: Core algorithms . London, Springer, 2009. [8] BURGER, W., BURGE, M. J. Principles of digital image processing. 3: Advanced methods . London, Springer, 2013. CHITYALA, R. Image processing and acquisition using Python . Boca Raton, FL, CRC Press, 2014. Trabalhos complementares de aplica\u00e7\u00e3o [9] ESCUDERO, M., HERN\u00c1NDEZ-FONTES, J. V., HERN\u00c1NDEZ, I. D., MENDOZA, E. Virtual Level Analysis Applied to Wave Flume Experiments: The Case of Waves-Cubipod Homogeneous Low-Crested Structure Interaction , Journal of Marine Science and Engineering, v. 9, n. 2, p. 230, 22 fev. 2021. Dispon\u00edvel em: http://dx.doi.org/10.3390/jmse9020230 [10] HERN\u00c1NDEZ, I. D., HERN\u00c1NDEZ-FONTES, J. V., VITOLA, M. A., SILVA, M.C., ESPERAN\u00c7A P.T.T. Water elevation measurements using binary image analysis for 2D hydrodynamic experiments , Ocean Engineering, v. 157, p. 325\u2013338, jun. 2018. Dispon\u00edvel em: http://dx.doi.org/10.1016/j.oceaneng.2018.03.063 [11] SCHNEIDER, C. A., RASBAND, W. S., & ELICEIRI, K. W. NIH Image to ImageJ: 25 years of image analysis . Nature Methods, 2012. 9(7), 671\u2013675. Dispon\u00edvel em: http://dx.doi.org/10.1038/nmeth.2089 [12] LIU, JUN-PENG; VAZ, MURILO A.; CHEN, RONG-QI; DUAN, MENG-LAN; HERN\u00c1NDEZ, IRVING D. Axial Mechanical Experiments of Unbonded Flexible Pipes . Petroleum Science 17, 5 (Outubro 2020): 1400\u20131410. Dispon\u00edvel em: http://dx.doi.org/10.1007/s12182-020-00504-3 Avalia\u00e7\u00e3o A avalia\u00e7\u00e3o do curso seguir\u00e1 os seguintes crit\u00e9rios: ITEM DESCRI\u00c7\u00c3O Exame parcial: 30% ( Conte\u00fado dos Blocos 1 e 2 ) Projeto (*): 30% ( Ser\u00e3o definidos no final do Bloco 2 ) Exame final: 40% ( Conte\u00fado dos Blocos 3 e 4 ) (*) O projeto poder\u00e1 ser desenvolvido individual ou coletivamente, e visa a aplica\u00e7\u00e3o dos conhecimentos adquiridos no curso para inferir propriedades, dimens\u00f5es ou caracter\u00edsticas de fen\u00f4menos/problemas da Engenharia Naval e Oce\u00e2nica a partir de imagens digitais 2D. Docente D.Sc. Irving David Hern\u00e1ndez Fontes","title":"Class Syllabus"},{"location":"COV%20816/ementa/#ementa-da-disciplina","text":"COV 816 - PROCESSAMENTO DE IMAGENS (PROGRAMA DE ENG\u00aa OCE\u00c2NICA - 2023/1)","title":"EMENTA DA DISCIPLINA"},{"location":"COV%20816/ementa/#identificacao","text":"ITEM DESCRI\u00c7\u00c3O NOME: PROCESSAMENTO E AN\u00c1LISE DE IMAGENS NA ENGENHARIA NAVAL E OCE\u00c2NICA C\u00d3DIGO: COV-816 CARGA HOR\u00c1RIA: 45 HORAS \u00c1REA: ENGENHARIAS/ENGENHARIA NAVAL E OCE\u00c2NICA CR\u00c9DITOS: 3,0","title":"Identifica\u00e7\u00e3o"},{"location":"COV%20816/ementa/#publico-alvo","text":"Estudantes de gradua\u00e7\u00e3o e p\u00f3s-gradua\u00e7\u00e3o que atuem nas \u00e1reas de engenharia.","title":"P\u00fablico Alvo"},{"location":"COV%20816/ementa/#objetivos","text":"GERAL: Proporcionar aos alunos um estudo aprofundado dos princ\u00edpios e t\u00e9cnicas de processamento de imagens nos seguintes t\u00f3picos: Aquisi\u00e7\u00e3o de imagens (equipamentos, amostragem, quantiza\u00e7\u00e3o e representa\u00e7\u00e3o de cores). Aprimoramento de imagens digitais no dom\u00ednios espacial (suaviza\u00e7\u00e3o de nitidez, detec\u00e7\u00e3o de bordas, limiariza\u00e7\u00e3o, equaliza\u00e7\u00e3o de histogramas, opera\u00e7\u00f5es morfol\u00f3gicas). Convers\u00e3o, segmenta\u00e7\u00e3o e representa\u00e7\u00e3o de imagens. Identifica\u00e7\u00e3o e seguimento de padr\u00f5es. Automa\u00e7\u00e3o dos modelos de processamento de imagens. ESPEC\u00cdFICO: Ao final do curso, os estudantes devem ser capazes de projetar e implementar operadores e processamentos diversos sobre imagens digitais de diversas modalidades e protocolos em problemas de estudo da Engenharia Naval e Oce\u00e2nica.","title":"Objetivos"},{"location":"COV%20816/ementa/#metodologia","text":"A disciplina est\u00e1 dividida em cinco blocos, cujos conte\u00fados ser\u00e3o ministrados com base em um plano particular de trabalho, e duas avalia\u00e7\u00f5es. Os blocos com seus conte\u00fados e planos de trabalho, e os pontos de avalia\u00e7\u00e3o, s\u00e3o discriminados na tabela a seguir:","title":"Metodologia"},{"location":"COV%20816/ementa/#bloco-1-conceitos-basicos-4-aulas","text":"CONTE\u00daDO: - Defini\u00e7\u00e3o da Imagem Digital: Conceito geral da imagem digital e suas propriedades principais - Tipos de Imagens e Arquivos de Imagem: Imagens em tons de cinza, imagens a cor, e imagens complexas. - Espa\u00e7os de cor: Apresenta\u00e7\u00e3o dos principais espa\u00e7os de cor usados nas imagens digitais (RGB, HSL, CIE-Lab). - Apresenta\u00e7\u00e3o do conte\u00fado do curso. PLANO DE TRABALHO: - Aplica\u00e7\u00e3o ao vivo dos conceitos no software ImageJ/FIJI. - Estudo da t\u00e9cnica de fotoluminesc\u00eancia. - Opera\u00e7\u00f5es de cor e pseudo-cor nas imagens. - Melhora digital das imagens.","title":"Bloco 1 - Conceitos b\u00e1sicos (4 aulas)"},{"location":"COV%20816/ementa/#bloco-2-aquisicao-de-imagens-4-aulas","text":"CONTE\u00daDO: - Aquisi\u00e7\u00e3o de imagens: Conceitos de Resolu\u00e7\u00e3o, Contraste, Profundidade de Campo, Perspectiva, Distor\u00e7\u00e3o. - Calibra\u00e7\u00e3o Espacial: Processo de Calibra\u00e7\u00e3o, Sistema de Coordenadas, Algoritmos de Calibra\u00e7\u00e3o, Corre\u00e7\u00f5es de Imagem. PLANO DE TRABALHO: - Aquisi\u00e7\u00e3o de imagens com webcam. - Aquisi\u00e7\u00e3o de imagens com c\u00e2meras de uso industrial/cient\u00edfico. - Rectifica\u00e7\u00e3o de imagens. - Correla\u00e7\u00e3o de unidades de imagem e do mundo real. - Protocolos de calibra\u00e7\u00e3o. EXAME PARCIAL (B1 - B2)","title":"Bloco 2 - Aquisi\u00e7\u00e3o de imagens (4 aulas)"},{"location":"COV%20816/ementa/#bloco-3-analise-e-processamento-de-imagens-6-aulas","text":"CONTE\u00daDO: An\u00e1lise de imagens: Histograma, Linha de Perfil, Medidas de Intensidade. Processamento de imagens: LUT, Convolu\u00e7\u00e3o, Filtros Espaciais, Binariza\u00e7\u00e3o, Morfologia de Imagens Bin\u00e1rias, Detec\u00e7\u00e3o de Bordas. PLANO DE TRABALHO: Filtragem das imagens retificadas no Bloco 2. Medi\u00e7\u00e3o de part\u00edculas e elementos da imagem. Programa\u00e7\u00e3o de Macros. Automa\u00e7\u00e3o do processamento e filtragem dos elementos da imagem digital.","title":"Bloco 3 -  An\u00e1lise e processamento de imagens (6 aulas)"},{"location":"COV%20816/ementa/#bloco-4-metrologia-por-imagens-6-aulas","text":"CONTE\u00daDO: Medi\u00e7\u00e3o em imagens: Medi\u00e7\u00e3o de regi\u00f5es, medi\u00e7\u00e3o de part\u00edculas. Segmenta\u00e7\u00e3o e Classifica\u00e7\u00e3o: T\u00e9cnicas de segmenta\u00e7\u00e3o de objetos e classifica\u00e7\u00e3o de part\u00edculas, automa\u00e7\u00e3o do processo de medi\u00e7\u00e3o/classifica\u00e7\u00e3o. PLANO DE TRABALHO: Filtragem das imagens retificadas no Bloco 2. Medi\u00e7\u00e3o de part\u00edculas e elementos da imagem. Programa\u00e7\u00e3o de Macros. Automa\u00e7\u00e3o do processamento e filtragem dos elementos da imagem digital.","title":"Bloco 4 - Metrologia por imagens (6 aulas)"},{"location":"COV%20816/ementa/#bloco-5-apresentacoes-de-projetos-por-equipe-2-aulas","text":"CONTE\u00daDO: Discuss\u00e3o geral e resolu\u00e7\u00e3o de d\u00favidas gerais do curso. PLANO DE TRABALHO: Equipes apresentam projeto de processamento de imagens aplicado a problemas de relev\u00e2ncia da \u00e1rea de estudo. EXAME FINAL (B3 - B4)","title":"Bloco 5 - Apresenta\u00e7\u00f5es de Projetos por Equipe (2 aulas)"},{"location":"COV%20816/ementa/#ementa","text":"BLOCO DESCRI\u00c7\u00c3O B1 - Conceitos b\u00e1sicos Defini\u00e7\u00e3o da Imagem Digital: Conceito geral da imagem digital e suas propriedades principais. Tipos de Imagens e Arquivos de Imagem: Imagens em tons de cinza, imagens a cor, e imagens complexas. Espa\u00e7os de cor: Apresenta\u00e7\u00e3o dos espa\u00e7os de cor RGB, HSL e CIE-Lab usados nas imagens digitais. B2 - Aquisi\u00e7\u00e3o de imagens Aquisi\u00e7\u00e3o de imagens: Conceitos de Resolu\u00e7\u00e3o, Contraste, Profundidade de Campo, Perspectiva, Distor\u00e7\u00e3o. Calibra\u00e7\u00e3o Espacial: Processo de Calibra\u00e7\u00e3o, Sistema de Coordenadas, Algoritmos de Calibra\u00e7\u00e3o, Corre\u00e7\u00f5es de Imagem. B3 - An\u00e1lise e processamento de imagens An\u00e1lise de imagens: Histograma, Linha de Perfil, Medidas de Intensidade. Processamento de imagens: Convolu\u00e7\u00e3o, Filtros Espaciais, Binariza\u00e7\u00e3o, Morfologia de Imagens Bin\u00e1rias, Detec\u00e7\u00e3o de Bordas. B4 - Metrologia por imagens Medi\u00e7\u00e3o em imagens: Medi\u00e7\u00e3o de regi\u00f5es, medi\u00e7\u00e3o de part\u00edculas. Segmenta\u00e7\u00e3o e Classifica\u00e7\u00e3o: T\u00e9cnicas de segmenta\u00e7\u00e3o de objetos e classifica\u00e7\u00e3o de part\u00edculas, automa\u00e7\u00e3o do processo de medi\u00e7\u00e3o/classifica\u00e7\u00e3o. B5 - Apresenta\u00e7\u00e3o de Projetos Discuss\u00e3o geral e resolu\u00e7\u00e3o de d\u00favidas gerais do curso.","title":"Ementa"},{"location":"COV%20816/ementa/#bibliografia","text":"","title":"Bibliografia"},{"location":"COV%20816/ementa/#bibliografia-complementar-livro-didatico","text":"[1] BURGER, W., BURGE, M. J. Principles of digital image processing. 1: Fundamental techniques . London, Springer, 2009. Conceitos B\u00e1sicos [2] GONZALEZ, R. C., WOODS, R. E. Digital image processing . 2nd ed., Internat. Upper Saddle River, NJ, Prentice-Hall, 2002. [3] J\u00c4HNE, B. Digital image processing. 6th ed. Berlin\u202f; New York, Springer, 2005. [4] SZELISKI, R. Computer vision: algorithms and applications . London Heidelberg, Springer, 2011. Aquisi\u00e7\u00e3o, an\u00e1lise e processamento de imagens [5] CORKE, P. I. Robotics, vision and control: fundamental algorithms in MATLAB . Berlin, Springer, 2011. (Springer tracts in advanced robotics, v. 73). [6] RELF, C. G. Image acquisition and processing with LabVIEW. Boca Raton , CRC Press, 2004. (Image processing series). T\u00e9cnicas de Processamento de Imagens [7] BURGER, W., BURGE, M. J. Principles of digital image processing. 2: Core algorithms . London, Springer, 2009. [8] BURGER, W., BURGE, M. J. Principles of digital image processing. 3: Advanced methods . London, Springer, 2013. CHITYALA, R. Image processing and acquisition using Python . Boca Raton, FL, CRC Press, 2014.","title":"Bibliografia Complementar (Livro did\u00e1tico)"},{"location":"COV%20816/ementa/#trabalhos-complementares-de-aplicacao","text":"[9] ESCUDERO, M., HERN\u00c1NDEZ-FONTES, J. V., HERN\u00c1NDEZ, I. D., MENDOZA, E. Virtual Level Analysis Applied to Wave Flume Experiments: The Case of Waves-Cubipod Homogeneous Low-Crested Structure Interaction , Journal of Marine Science and Engineering, v. 9, n. 2, p. 230, 22 fev. 2021. Dispon\u00edvel em: http://dx.doi.org/10.3390/jmse9020230 [10] HERN\u00c1NDEZ, I. D., HERN\u00c1NDEZ-FONTES, J. V., VITOLA, M. A., SILVA, M.C., ESPERAN\u00c7A P.T.T. Water elevation measurements using binary image analysis for 2D hydrodynamic experiments , Ocean Engineering, v. 157, p. 325\u2013338, jun. 2018. Dispon\u00edvel em: http://dx.doi.org/10.1016/j.oceaneng.2018.03.063 [11] SCHNEIDER, C. A., RASBAND, W. S., & ELICEIRI, K. W. NIH Image to ImageJ: 25 years of image analysis . Nature Methods, 2012. 9(7), 671\u2013675. Dispon\u00edvel em: http://dx.doi.org/10.1038/nmeth.2089 [12] LIU, JUN-PENG; VAZ, MURILO A.; CHEN, RONG-QI; DUAN, MENG-LAN; HERN\u00c1NDEZ, IRVING D. Axial Mechanical Experiments of Unbonded Flexible Pipes . Petroleum Science 17, 5 (Outubro 2020): 1400\u20131410. Dispon\u00edvel em: http://dx.doi.org/10.1007/s12182-020-00504-3","title":"Trabalhos complementares de aplica\u00e7\u00e3o"},{"location":"COV%20816/ementa/#avaliacao","text":"A avalia\u00e7\u00e3o do curso seguir\u00e1 os seguintes crit\u00e9rios: ITEM DESCRI\u00c7\u00c3O Exame parcial: 30% ( Conte\u00fado dos Blocos 1 e 2 ) Projeto (*): 30% ( Ser\u00e3o definidos no final do Bloco 2 ) Exame final: 40% ( Conte\u00fado dos Blocos 3 e 4 ) (*) O projeto poder\u00e1 ser desenvolvido individual ou coletivamente, e visa a aplica\u00e7\u00e3o dos conhecimentos adquiridos no curso para inferir propriedades, dimens\u00f5es ou caracter\u00edsticas de fen\u00f4menos/problemas da Engenharia Naval e Oce\u00e2nica a partir de imagens digitais 2D.","title":"Avalia\u00e7\u00e3o"},{"location":"COV%20816/ementa/#docente","text":"D.Sc. Irving David Hern\u00e1ndez Fontes","title":"Docente"}]}